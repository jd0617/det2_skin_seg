{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import Boxes, BoxMode\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_handles = []\n",
    "\n",
    "        # register hooks\n",
    "        self.hook_handles.append(target_layer.register_forward_hook(self._save_activation))\n",
    "        self.hook_handles.append(target_layer.register_backward_hook(self._save_gradient))\n",
    "\n",
    "    def _save_activation(self, module, input, output):\n",
    "        if output.ndim == 3:\n",
    "            output = output.unsqueeze(0)\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def _save_gradient(self, module, grad_input, grad_output):\n",
    "        grad = grad_output[0]\n",
    "        if grad.ndim == 3:\n",
    "            grad = grad.unsqueeze(0)\n",
    "        self.gradients = grad.detach()\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hook_handles:\n",
    "            h.remove()\n",
    "\n",
    "    def __call__(self, input_tensor, class_idx=None):\n",
    "        # Forward\n",
    "        output = self.model(input_tensor)\n",
    "        \n",
    "        # If it's a detection model, you'll need to pick a score or logit\n",
    "        if class_idx is None:\n",
    "            score = output[0][\"instances\"].scores[0]  # first detection\n",
    "        else:\n",
    "            # print(\"class_idx: \", class_idx)\n",
    "            # print(output[0])\n",
    "            score = output[0][\"instances\"].scores[int(class_idx)]\n",
    "\n",
    "        # Backward\n",
    "        self.model.zero_grad()\n",
    "        score.backward(retain_graph=True)\n",
    "\n",
    "        # Global-average-pool gradients\n",
    "        weights = self.gradients.mean(dim=[2, 3], keepdim=True)  # [C,1,1]\n",
    "\n",
    "        # Weighted sum of activations\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        \n",
    "        # Normalize to [0,1]\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        return cam\n",
    "\n",
    "\n",
    "# ---- Visualizer helper ----\n",
    "def draw_predictions(img, outputs, metadata, gt_boxes, gt_classes):\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.0)\n",
    "    inst = outputs[\"instances\"].to(\"cpu\")\n",
    "    # v = v.draw_instance_predictions(inst)\n",
    "\n",
    "    # if gt_boxes is not None:\n",
    "        # Draw GT boxes in red\n",
    "    for box, cls in zip(gt_boxes, gt_classes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cls_name = metadata.thing_classes[cls] if len(metadata.thing_classes) > 0 else str(cls)\n",
    "        text = f\"GT: {cls_name}\"\n",
    "\n",
    "        v.draw_box([x1, y1, x2, y2], edge_color=(0.0,1.0,0.0))\n",
    "        v.draw_text(text, (x1, y1), color=(0.0,1.0,0.0))\n",
    "\n",
    "    boxes = inst.pred_boxes.tensor.numpy()\n",
    "    scores = inst.scores.tolist()\n",
    "    classes = inst.pred_classes.tolist()\n",
    "\n",
    "    for box, score, cls_id in zip(boxes, scores, classes):\n",
    "        x0, y0, x1, y1 = box\n",
    "        cls_name = metadata.thing_classes[cls_id] if len(metadata.thing_classes) > 0 else str(cls_id)\n",
    "        text = f\"Pred: {cls_name} {score:.2f}\"\n",
    "\n",
    "        v.draw_box([x0, y0, x1, y1], edge_color=(1.0, 0.0, 0.0))\n",
    "        v.draw_text(text, (x0, y0), color=(1.0, 0.0, 0.0))\n",
    "\n",
    "    vis_out = v.output\n",
    "    drawn = vis_out.get_image()[:, :, ::-1]\n",
    "\n",
    "    return drawn\n",
    "\n",
    "\n",
    "def get_gt_from_dict(entry):\n",
    "    gt_boxes, gt_classes = [], []\n",
    "    for ann in entry[\"annotations\"]:\n",
    "        bbox = ann[\"bbox\"]\n",
    "        if ann[\"bbox_mode\"] != BoxMode.XYXY_ABS:\n",
    "            bbox = BoxMode.convert(bbox, ann[\"bbox_mode\"], BoxMode.XYXY_ABS)\n",
    "        gt_boxes.append(bbox)\n",
    "        gt_classes.append(ann[\"category_id\"])\n",
    "    return gt_boxes, gt_classes  \n",
    "\n",
    "\n",
    "# ---- Main routine for one image ----\n",
    "def visualize_cam_and_bboxes(entry, model, gradcam, metadata, out_dir):\n",
    "    img_path = entry[\"file_name\"]\n",
    "    h, w = entry[\"height\"], entry[\"width\"]\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Detectron2 input\n",
    "    inputs = [{\"image\": torch.as_tensor(img.astype(\"float32\").transpose(2, 0, 1)).cuda(),\n",
    "               \"height\": h, \"width\": w}]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    # Grad-CAM on top detection (if any)\n",
    "    if len(outputs[0][\"instances\"]) > 0:\n",
    "        score = outputs[0][\"instances\"].scores[0]\n",
    "        cam_map = gradcam(inputs, score)\n",
    "        cam_resized = cv2.resize(cam_map, (w, h))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "        overlay = (0.5 * heatmap + 0.5 * img).astype(np.uint8)\n",
    "    else:\n",
    "        overlay = img.copy()\n",
    "\n",
    "    # GT boxes\n",
    "    gt_boxes, gt_classes = get_gt_from_dict(entry)\n",
    "\n",
    "    # print(\"GT boxes:\", gt_boxes[:3])\n",
    "    # print(\"GT classes:\", gt_classes[:3])\n",
    "\n",
    "    # Pred + GT\n",
    "    bbox_vis = draw_predictions(img.copy(), outputs[0], metadata, gt_boxes, gt_classes)\n",
    "\n",
    "    # Stack horizontally\n",
    "    stacked = np.hstack([overlay, bbox_vis])\n",
    "\n",
    "    # Save\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    out_path = Path(out_dir) / Path(img_path).name\n",
    "    cv2.imwrite(str(out_path), stacked)\n",
    "    print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "078cca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import _init_paths\n",
    "from config import cfg, update_config\n",
    "\n",
    "def update_cfg_with_args(cfg, arg_key, arg_value):\n",
    "    cfg.defrost()\n",
    "\n",
    "    arg_key = arg_key.upper()\n",
    "\n",
    "    cfg.arg_key = arg_value\n",
    "\n",
    "    cfg.freeze()\n",
    "\n",
    "\n",
    "minmax_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "def minmax_norm(img):\n",
    "    img = np.array([\n",
    "        minmax_scaler.fit_transform(img[:, :, 0]),\n",
    "        minmax_scaler.fit_transform(img[:, :, 1]),\n",
    "        minmax_scaler.fit_transform(img[:, :, 2]),\n",
    "    ])\n",
    "\n",
    "    return np.transpose(img, (1, 2, 0)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68815a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/workspace/project/configs/frcnn/frcnn.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Instances(num_instances=6, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 253.8135,   87.3590,  362.0257,  197.7949],\n",
      "        [ 235.2458,  296.0808,  351.4508,  405.0326],\n",
      "        [ 233.0878,  978.2848,  347.1781, 1095.5038],\n",
      "        [ 239.2220,  512.9576,  356.4888,  626.9459],\n",
      "        [ 239.2888,  748.5310,  361.6597,  873.8732],\n",
      "        [ 233.6026,  746.5156,  359.2216,  875.2394]])), scores: tensor([1.0000, 1.0000, 0.9999, 0.9993, 0.9765, 0.1430]), pred_classes: tensor([0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw1_09-D2(30m)-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  87.3732,  788.4876,  196.5059,  896.8377],\n",
      "        [  94.6170,  307.0933,  205.9943,  419.1758],\n",
      "        [  93.2583,   95.2293,  206.4622,  210.0879],\n",
      "        [ 103.3276, 1019.2393,  206.1108, 1122.8838],\n",
      "        [ 398.1685, 1017.9677,  499.3303, 1119.8344],\n",
      "        [ 237.0203,  927.5140,  353.1707, 1040.3225],\n",
      "        [ 259.8050,  689.9818,  362.6346,  791.3562],\n",
      "        [ 400.4636,  801.8005,  500.0779,  903.9296],\n",
      "        [ 266.6750,  248.3050,  362.9833,  344.5712],\n",
      "        [ 252.0018,  477.6390,  362.0543,  594.1254],\n",
      "        [ 404.1386,  351.4181,  510.1773,  453.1386],\n",
      "        [ 389.8467,  561.6180,  501.6767,  673.8361],\n",
      "        [  82.6073,  534.4041,  195.0396,  647.8557],\n",
      "        [ 255.4333,   33.5069,  359.4947,  137.3125],\n",
      "        [ 409.5235,  127.9151,  519.0797,  235.2624],\n",
      "        [ 410.2410,  130.0424,  517.3726,  237.3010]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "        0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9982, 0.0925]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw1_09-D2(30m)-1.JPG\n",
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 101.2961,  109.2132,  211.1395,  219.9617],\n",
      "        [ 246.1480,  695.6925,  361.6031,  811.6644],\n",
      "        [  94.7290,  336.5607,  206.6735,  450.5845],\n",
      "        [ 401.7399, 1020.8060,  510.6373, 1129.0950],\n",
      "        [  80.1823,  794.9146,  200.5255,  910.2087],\n",
      "        [ 246.0021,  922.1040,  359.3475, 1033.8145],\n",
      "        [ 253.6511,  223.6552,  365.3137,  336.4216],\n",
      "        [ 262.3408,   10.6846,  384.7446,  134.3389],\n",
      "        [ 413.2547,  315.7060,  532.5112,  432.2522],\n",
      "        [ 243.4426,  451.5676,  364.5189,  573.7424],\n",
      "        [ 402.6228,  554.1588,  524.7939,  676.1768],\n",
      "        [ 427.5583,   96.8236,  539.7554,  212.1700],\n",
      "        [  81.5365,  563.0623,  196.1634,  679.5111],\n",
      "        [ 402.4662,  786.4688,  522.4414,  904.6516],\n",
      "        [  94.5576, 1017.1521,  207.8097, 1118.4670],\n",
      "        [  94.5576, 1017.1521,  207.8097, 1118.4670]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9999, 0.9990, 0.9976, 0.2484, 0.0985]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw1_09-D2(30m)-2.JPG\n",
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 396.5989,   96.2288,  508.0518,  209.4258],\n",
      "        [ 391.3730,  320.4765,  505.0112,  429.3798],\n",
      "        [  95.9788,   97.9445,  198.0062,  200.6498],\n",
      "        [ 238.8163,  222.3109,  354.1049,  336.4745],\n",
      "        [  69.5272,  558.2368,  177.4106,  662.4119],\n",
      "        [  69.4329, 1015.9023,  184.5721, 1131.1428],\n",
      "        [ 381.2610,  549.6434,  498.7427,  664.1819],\n",
      "        [ 224.9072,  928.0823,  346.5515, 1045.6707],\n",
      "        [ 382.1563,  791.2375,  503.4741,  907.2330],\n",
      "        [ 224.9181,  690.6039,  342.1930,  807.2470],\n",
      "        [ 382.5124, 1013.2026,  492.1258, 1120.9634],\n",
      "        [  83.5555,  329.1511,  185.7779,  432.8479],\n",
      "        [  76.2592,  794.0834,  184.3438,  904.1136],\n",
      "        [ 235.0916,  460.7682,  344.2187,  573.9139],\n",
      "        [ 257.9745,   10.8467,  382.7345,  118.3381],\n",
      "        [ 256.0582,    5.3430,  373.2667,  118.8778]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9999, 0.9998, 0.9998, 0.9997, 0.8432, 0.4988]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw1_09-D2(30m)-3.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  69.7989,  823.7754,  165.8402,  921.9619],\n",
      "        [  66.9677,  593.5336,  166.9184,  694.9659],\n",
      "        [  65.3308,  333.5056,  182.1499,  455.4660],\n",
      "        [ 382.2755,  584.2447,  499.6304,  693.6367],\n",
      "        [ 373.4263,  818.8137,  501.7294,  943.9172],\n",
      "        [  73.4191,  111.7736,  186.1871,  221.9413],\n",
      "        [ 230.1798,  488.5302,  335.6579,  593.1989],\n",
      "        [ 416.8596,  351.3519,  530.8886,  471.1376],\n",
      "        [ 405.3677, 1060.3827,  520.0048, 1161.5917],\n",
      "        [ 208.7379,  981.3774,  323.4543, 1079.7495],\n",
      "        [ 238.2469,  748.2274,  329.9914,  876.5833],\n",
      "        [ 208.7379,  981.3774,  323.4543, 1079.7495],\n",
      "        [ 428.9573,  353.4467,  534.9952,  469.0613],\n",
      "        [ 232.7546,  486.9956,  334.7918,  597.7000],\n",
      "        [ 404.4569, 1058.9764,  524.2836, 1162.8339],\n",
      "        [  69.7443,  115.6110,  186.2870,  222.5951],\n",
      "        [ 381.4818,  582.7471,  504.3656,  697.4692]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 0.9989, 0.9888, 0.9359, 0.9200,\n",
      "        0.7305, 0.2343, 0.1953, 0.1782, 0.1237, 0.0798, 0.0759, 0.0652]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw1_09-D3(24h)-3.JPG\n",
      "Instances(num_instances=6, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 251.2567, 1023.5155,  365.5088, 1139.6344],\n",
      "        [ 250.0602,  571.0854,  370.6794,  695.8846],\n",
      "        [ 243.3045,  124.0713,  356.4245,  241.6432],\n",
      "        [ 242.0117,  802.2115,  360.2749,  925.6448],\n",
      "        [ 243.5312,  319.0669,  370.3659,  431.0992],\n",
      "        [ 245.4916,  328.0879,  373.5144,  447.6122]])), scores: tensor([1.0000, 0.9994, 0.9994, 0.9976, 0.4722, 0.0707]), pred_classes: tensor([0, 0, 0, 0, 1, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw1_09-D3(24h)-4.JPG\n",
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 247.6323,  568.5706,  369.3969,  695.5961],\n",
      "        [ 232.3840, 1009.1713,  353.3326, 1129.3959],\n",
      "        [ 256.9310,   87.6597,  374.2408,  210.0508],\n",
      "        [ 225.9642,  787.4147,  366.2566,  924.4209],\n",
      "        [ 239.1751,  326.4268,  377.8993,  453.6494]])), scores: tensor([1.0000, 0.9999, 0.9999, 0.9999, 0.9998]), pred_classes: tensor([0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw1_28-D2(30m)-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 246.3387,  676.8840,  357.5381,  788.1092],\n",
      "        [ 412.0925,  288.2757,  526.4485,  404.3781],\n",
      "        [  69.8066,  533.8962,  181.4236,  646.3994],\n",
      "        [ 409.1802,  762.0404,  526.9724,  879.9886],\n",
      "        [  77.1657, 1016.3120,  199.8257, 1139.0796],\n",
      "        [ 233.4347,  203.5237,  353.7301,  320.0100],\n",
      "        [ 397.1422,  521.2788,  521.7813,  644.9482],\n",
      "        [  92.6850,   84.2739,  197.5090,  189.1781],\n",
      "        [ 253.4223,  920.7214,  360.2481, 1027.1001],\n",
      "        [  64.9786,  771.8538,  182.9624,  900.1217],\n",
      "        [ 244.6488,  426.3801,  354.6407,  538.8325],\n",
      "        [ 420.4557,   77.0544,  527.8376,  181.0220],\n",
      "        [ 394.4043, 1006.7188,  515.6467, 1128.7039],\n",
      "        [  65.3006,  285.4406,  174.6566,  396.8591],\n",
      "        [  64.0991,  283.8604,  174.3027,  393.7803],\n",
      "        [ 416.8857,   74.2491,  530.8195,  181.0150]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9998, 0.9998,\n",
      "        0.9994, 0.9984, 0.9951, 0.9947, 0.9878, 0.2611, 0.1835]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])])\n",
      "Saved: gradcam_results/raw1_28-D2(30m)-3.JPG\n",
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  89.5328, 1007.5148,  197.6805, 1113.4083],\n",
      "        [  88.7758,  509.6556,  194.8860,  615.8903],\n",
      "        [ 243.2869,  912.3783,  359.0126, 1025.4773],\n",
      "        [  84.7525,  768.6946,  187.6357,  871.6070],\n",
      "        [ 424.0098,  512.0746,  539.3242,  629.1177],\n",
      "        [ 419.6483,   61.3608,  527.9442,  168.4895],\n",
      "        [ 417.5288,  768.0126,  533.0051,  878.3912],\n",
      "        [ 254.9655,  667.8337,  372.0905,  788.0511],\n",
      "        [ 418.9099, 1003.9921,  528.8474, 1113.9894],\n",
      "        [  93.2064,   40.2552,  205.9644,  151.2047],\n",
      "        [ 423.2076,  288.1611,  535.9595,  401.5894],\n",
      "        [ 263.9188,  180.3433,  368.9075,  286.5526],\n",
      "        [ 102.1014,  259.8390,  204.5768,  363.2407],\n",
      "        [ 262.1849,    0.0000,  379.7639,   95.2153],\n",
      "        [ 277.4186,  425.9373,  373.9143,  529.0922],\n",
      "        [  97.8265,  258.7351,  203.9405,  362.6399],\n",
      "        [ 277.4186,  425.9373,  373.9143,  529.0922]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "        0.9998, 0.9997, 0.9997, 0.9986, 0.9866, 0.1064, 0.1021, 0.0897]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw1_33-D2(30m)-1.JPG\n",
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 241.1875,  191.8957,  355.3487,  305.5554],\n",
      "        [ 246.6670,    0.0000,  361.3220,  100.9035],\n",
      "        [ 412.1468,   65.6437,  521.8481,  175.7687],\n",
      "        [ 417.8245,  299.6721,  532.4164,  414.3730],\n",
      "        [  62.8230,  540.3860,  178.5549,  652.6231],\n",
      "        [ 241.6982,  439.5404,  362.9352,  556.1796],\n",
      "        [  66.9191,  298.7491,  175.7159,  406.5322],\n",
      "        [ 417.0608,  804.0869,  527.6512,  911.9159],\n",
      "        [ 404.1100, 1028.2385,  516.7078, 1143.2170],\n",
      "        [  69.4272,   62.9987,  176.8966,  172.6083],\n",
      "        [ 253.9910,  697.1141,  370.2365,  803.0420],\n",
      "        [ 421.7852,  550.6143,  532.2715,  661.0621],\n",
      "        [  72.4937, 1029.6155,  189.4939, 1149.8071],\n",
      "        [ 243.7419,  937.8013,  357.7550, 1049.9805],\n",
      "        [  65.4560,  814.0848,  172.7702,  923.3065],\n",
      "        [  65.4560,  814.0848,  172.7702,  923.3065]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "        0.9999, 0.9998, 0.9996, 0.9984, 0.9982, 0.6697, 0.1694]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])])\n",
      "Saved: gradcam_results/raw1_33-D2(30m)-2.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  89.2852,   92.2229,  200.1339,  205.4257],\n",
      "        [  73.2690,  340.4881,  184.5843,  453.6893],\n",
      "        [  60.8189, 1017.7545,  174.3926, 1129.3595],\n",
      "        [ 238.7440,  237.0826,  354.1962,  354.6626],\n",
      "        [ 227.7771,  715.9579,  335.1742,  825.5477],\n",
      "        [  64.9477,  811.5994,  178.7437,  920.9699],\n",
      "        [ 402.3288,   93.0731,  515.6771,  207.0303],\n",
      "        [  66.5577,  577.1821,  177.0535,  690.0350],\n",
      "        [ 400.5041, 1017.0825,  514.7339, 1131.1476],\n",
      "        [ 253.2172,    3.4469,  370.3117,  119.0299],\n",
      "        [ 223.0840,  930.8557,  342.0562, 1048.8070],\n",
      "        [ 233.2390,  491.8542,  352.3846,  611.0956],\n",
      "        [ 390.0248,  811.4269,  495.4993,  912.4909],\n",
      "        [ 392.5671,  587.9528,  496.0466,  688.4915],\n",
      "        [ 397.9892,  349.1249,  505.2719,  455.2413]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9998]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw1_33-D2(30m)-3.JPG\n",
      "Instances(num_instances=21, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  88.0324,  831.2491,  195.7644,  942.8669],\n",
      "        [ 100.6804,  561.9337,  217.7841,  679.2266],\n",
      "        [ 429.3286,  573.4433,  553.3082,  690.4057],\n",
      "        [  96.3148,   80.1728,  217.5793,  194.1998],\n",
      "        [ 283.2225,  457.0174,  395.7389,  576.0862],\n",
      "        [ 273.2331,  956.1119,  380.5136, 1066.0150],\n",
      "        [ 451.0541,   84.7979,  553.3021,  187.4229],\n",
      "        [ 283.6171,    0.0000,  389.7269,  112.9878],\n",
      "        [ 423.0999, 1045.8418,  528.2910, 1159.2859],\n",
      "        [ 272.0445,  731.7732,  384.5755,  840.8629],\n",
      "        [ 280.9954,    0.0000,  400.1282,  108.1987],\n",
      "        [  77.7387,  320.2374,  171.6113,  423.5441],\n",
      "        [ 444.4617,  307.3818,  543.1795,  435.5398],\n",
      "        [ 448.9787,   85.6607,  552.2873,  186.0500],\n",
      "        [ 280.1416,  443.0887,  389.3082,  577.5459],\n",
      "        [  79.0893,  322.4131,  173.0427,  421.5881],\n",
      "        [ 425.5748, 1049.6042,  530.6652, 1156.8762],\n",
      "        [ 272.0445,  731.7732,  384.5755,  840.8629],\n",
      "        [ 272.7802,  957.1108,  375.9694, 1061.8969],\n",
      "        [ 430.1829,  572.9949,  551.9183,  695.0347],\n",
      "        [ 246.3187,  227.3090,  356.2192,  331.4166]])), scores: tensor([0.9999, 0.9996, 0.9972, 0.9949, 0.9904, 0.9886, 0.9759, 0.8913, 0.8768,\n",
      "        0.8087, 0.6096, 0.5674, 0.3942, 0.3666, 0.3481, 0.2450, 0.1760, 0.0939,\n",
      "        0.0708, 0.0703, 0.0541]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw1_33-D3(24h)-2.JPG\n",
      "Instances(num_instances=6, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 255.4873, 1035.0479,  364.0098, 1145.3936],\n",
      "        [ 239.6972,  123.1734,  357.0646,  233.4998],\n",
      "        [ 248.2561,  616.6842,  363.8160,  734.1710],\n",
      "        [ 251.9254,  831.7064,  373.0042,  953.8367],\n",
      "        [ 237.7917,  396.6913,  367.5246,  519.8517],\n",
      "        [ 238.4986,  399.1572,  368.5518,  519.7745]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9998, 0.9921, 0.0539]), pred_classes: tensor([0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw1_33-D2(30m)-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=8, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 251.9881,  620.3944,  364.7717,  733.4966],\n",
      "        [ 252.7675, 1025.5933,  354.5298, 1127.4160],\n",
      "        [ 251.9935,  829.0345,  366.5053,  944.8489],\n",
      "        [ 249.1374,  111.0007,  375.2135,  238.4839],\n",
      "        [ 243.1286,  383.8117,  355.8608,  487.8193],\n",
      "        [ 253.2460,  507.6831,  367.7169,  625.8149],\n",
      "        [ 244.7408,  386.6794,  355.8150,  505.8438],\n",
      "        [ 242.4611,  501.7348,  362.3875,  632.4156]])), scores: tensor([1.0000, 1.0000, 0.9998, 0.9996, 0.9374, 0.6131, 0.4126, 0.3883]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 1, 1])])\n",
      "Saved: gradcam_results/raw1_33-D3(24h)-4.JPG\n",
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 247.2289,  104.1191,  354.8659,  213.2839],\n",
      "        [ 253.4440,  340.0773,  367.5959,  453.0379],\n",
      "        [ 243.9833,  982.0844,  355.7839, 1088.1285],\n",
      "        [ 249.4677,  562.3835,  359.1478,  669.7631],\n",
      "        [ 247.6222,  779.5462,  359.8358,  893.5989]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999]), pred_classes: tensor([0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_02-D2(30m)-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 253.4799,   19.0898,  353.8558,  118.8050],\n",
      "        [  89.9259,  296.5898,  209.5139,  411.4896],\n",
      "        [ 429.3983,  548.2426,  544.0974,  658.7780],\n",
      "        [ 262.7346,  939.7818,  366.1750, 1041.9323],\n",
      "        [ 263.0081,  685.9785,  374.0477,  796.7398],\n",
      "        [ 429.5272,  792.3779,  549.8885,  912.0696],\n",
      "        [  98.0365,  778.9694,  212.4568,  893.2686],\n",
      "        [ 432.0043, 1010.2238,  536.4666, 1114.1117],\n",
      "        [ 271.4664,  459.3419,  376.9565,  564.2976],\n",
      "        [ 415.6049,   84.5308,  527.5477,  202.0358],\n",
      "        [  96.8906,  541.0833,  205.0390,  654.0387],\n",
      "        [ 429.6591,  335.6270,  537.3977,  438.8140],\n",
      "        [ 253.3421,  816.8293,  360.7126,  940.8574],\n",
      "        [ 105.4289, 1011.3922,  199.6979, 1102.8912],\n",
      "        [ 103.6291, 1015.3071,  200.7943, 1100.6453],\n",
      "        [  98.9242,  537.2841,  203.8711,  659.3690],\n",
      "        [ 102.5338,  141.5067,  215.1898,  230.9962]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9997, 0.9996,\n",
      "        0.9994, 0.9951, 0.8097, 0.7358, 0.6332, 0.3836, 0.1642, 0.1557]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0])])\n",
      "Saved: gradcam_results/raw2_02-D2(30m)-1.JPG\n",
      "Instances(num_instances=19, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 104.6045, 1001.8763,  200.5420, 1097.5820],\n",
      "        [  91.9209,   97.9128,  199.3911,  205.9222],\n",
      "        [ 249.4108,  230.2165,  361.7465,  340.7057],\n",
      "        [ 250.0048,  458.3387,  358.9461,  564.8984],\n",
      "        [ 422.4520,  782.6794,  536.2042,  898.7894],\n",
      "        [ 259.1177,   20.0359,  352.0842,  136.5029],\n",
      "        [ 253.8487,  919.3889,  366.6606, 1033.3900],\n",
      "        [ 412.9470,  996.8549,  529.2427, 1106.2213],\n",
      "        [  87.4206,  330.9804,  188.8741,  430.9478],\n",
      "        [ 421.4011,   88.4541,  528.0363,  198.5521],\n",
      "        [ 418.9468,  549.5010,  529.5826,  661.7429],\n",
      "        [  87.3676,  784.5865,  213.0870,  900.4541],\n",
      "        [ 427.5447,  317.6947,  534.2548,  425.9629],\n",
      "        [  90.1140,    0.0000,  219.9058,  120.3899],\n",
      "        [  87.2620,  547.3667,  198.4010,  668.0891],\n",
      "        [ 429.4032,  179.5149,  541.5731,  313.9131],\n",
      "        [ 292.0452,  785.3031,  395.1365,  888.9969],\n",
      "        [  84.7521,  547.8729,  196.7857,  665.8066],\n",
      "        [ 429.4032,  179.5149,  541.5731,  313.9131]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9999, 0.9996, 0.9995, 0.9970, 0.9856, 0.9776, 0.6972, 0.6247, 0.2469,\n",
      "        0.1115]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_02-D2(30m)-2.JPG\n",
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  80.1162,  797.5806,  190.4646,  908.3683],\n",
      "        [ 416.6928,  541.3803,  533.4590,  656.4028],\n",
      "        [  78.2163,  571.4498,  187.7194,  681.9387],\n",
      "        [ 243.2201,  693.4581,  361.7390,  813.8128],\n",
      "        [ 409.7191,  311.6337,  522.4265,  424.2594],\n",
      "        [ 238.9906,  483.4295,  355.8438,  600.0269],\n",
      "        [ 407.7310,   84.9241,  516.5612,  193.1109],\n",
      "        [ 252.0807,   26.3646,  361.9588,  136.7557],\n",
      "        [  79.2951,  326.1618,  187.7431,  433.9758],\n",
      "        [  82.3116,   96.1198,  191.4956,  205.3042],\n",
      "        [  78.0059, 1011.1892,  186.9583, 1121.9167],\n",
      "        [ 241.6645,  240.0869,  356.6645,  354.2220],\n",
      "        [ 429.6755,  992.7577,  541.2043, 1107.0292],\n",
      "        [ 422.7599,  775.9725,  537.8453,  887.5592],\n",
      "        [ 254.8852,  914.8658,  381.6108, 1036.8933],\n",
      "        [ 257.9497,  913.9291,  378.6357, 1036.8518]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9950, 0.0654]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw2_02-D2(30m)-3.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  94.4030,   68.8631,  196.4104,  170.9290],\n",
      "        [  91.2314,  299.1324,  201.1715,  411.7995],\n",
      "        [  85.5223, 1021.4534,  192.5483, 1128.5510],\n",
      "        [ 251.4776,  707.8483,  364.3971,  821.2739],\n",
      "        [ 247.6078,    8.9026,  372.1919,  123.4403],\n",
      "        [  85.9388,  530.3879,  204.1062,  647.9261],\n",
      "        [ 432.8590,   81.4782,  532.2258,  177.9679],\n",
      "        [ 436.8345, 1015.9005,  545.5177, 1126.7754],\n",
      "        [ 440.4696,  541.9894,  548.7366,  651.3569],\n",
      "        [ 440.3550,  788.5785,  544.8611,  894.4414],\n",
      "        [ 430.6410,  307.6904,  535.4147,  408.7795],\n",
      "        [  78.3482,  786.0769,  183.7130,  894.7112],\n",
      "        [ 272.1070,  448.1237,  388.7085,  567.4010],\n",
      "        [ 253.2151,  952.5116,  361.8156, 1048.8732],\n",
      "        [ 267.1603,  220.4055,  362.0697,  323.2608],\n",
      "        [ 253.2151,  952.5116,  361.8156, 1048.8732]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9998, 0.9996, 0.9987, 0.9979, 0.2760, 0.1877, 0.1341]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])])\n",
      "Saved: gradcam_results/raw2_06-D2(30m)-1.JPG\n",
      "Instances(num_instances=6, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 245.6587,   71.5425,  358.2195,  183.4491],\n",
      "        [ 244.1955,  506.5970,  360.3741,  622.8749],\n",
      "        [ 237.0432,  272.6957,  355.6521,  389.0967],\n",
      "        [ 242.9962,  727.7305,  368.0674,  845.7576],\n",
      "        [ 249.1870,  991.2126,  373.5501, 1103.8914],\n",
      "        [ 252.9483,  982.1680,  369.9628, 1101.3950]])), scores: tensor([1.0000, 0.9999, 0.9998, 0.9994, 0.9956, 0.0908]), pred_classes: tensor([0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw2_06-D2(30m)-4.JPG\n",
      "Instances(num_instances=20, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  66.0412,  800.4431,  169.9435,  902.3474],\n",
      "        [  76.2875,  106.8038,  193.6796,  231.8545],\n",
      "        [  65.6024,  569.8673,  176.9857,  682.2881],\n",
      "        [ 412.2391,  564.5252,  529.8235,  680.1409],\n",
      "        [  71.7928,  330.3098,  186.8456,  440.1577],\n",
      "        [  73.2590, 1023.5411,  178.7929, 1131.7161],\n",
      "        [ 234.6699,  263.0746,  353.6537,  377.0279],\n",
      "        [ 417.1055,   97.3791,  534.1359,  211.2802],\n",
      "        [ 217.0184,  937.8438,  332.4492, 1052.2733],\n",
      "        [ 235.7952,  722.6291,  353.4132,  839.3581],\n",
      "        [ 412.3198, 1026.0947,  529.2657, 1141.4712],\n",
      "        [ 418.4747,  894.1685,  530.3658, 1022.2350],\n",
      "        [ 406.7247, 1025.5884,  531.1291, 1138.0779],\n",
      "        [ 252.3803,   42.8079,  363.5975,  148.6793],\n",
      "        [ 439.3257,  796.8849,  542.4395,  904.3669],\n",
      "        [ 252.3803,   42.8079,  363.5975,  148.6793],\n",
      "        [ 420.7760,   99.0413,  531.0945,  210.1048],\n",
      "        [ 232.7357,  719.2526,  350.7401,  839.7112],\n",
      "        [ 417.9543,  897.9269,  532.3630, 1015.6014],\n",
      "        [ 441.1390,  328.5016,  546.8749,  424.7035]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 0.9995, 0.9995, 0.9992, 0.9954,\n",
      "        0.9891, 0.9459, 0.8747, 0.6307, 0.3462, 0.2219, 0.2204, 0.1868, 0.1408,\n",
      "        0.1246, 0.0875]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1])])\n",
      "Saved: gradcam_results/raw2_06-D2(30m)-2.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  83.9788,  987.0708,  200.3070, 1102.4187],\n",
      "        [ 419.8347,   60.1008,  529.7655,  170.3950],\n",
      "        [ 255.9686,  188.3293,  359.1154,  293.4054],\n",
      "        [ 253.2405,  420.7068,  378.0689,  543.8770],\n",
      "        [  91.9106,  270.6884,  203.4817,  381.4680],\n",
      "        [ 258.9775,  911.4367,  380.6249, 1034.8082],\n",
      "        [  89.4603,   56.2094,  200.6780,  164.5462],\n",
      "        [ 438.5490,  753.3093,  549.4035,  864.2611],\n",
      "        [ 430.0662,  271.8023,  550.7325,  391.6004],\n",
      "        [ 428.6878,  980.1967,  534.9443, 1090.9325],\n",
      "        [ 257.5300,  662.1656,  373.3664,  778.0771],\n",
      "        [  90.4431,  500.5049,  207.1733,  620.1229],\n",
      "        [  91.9714,  752.0434,  201.2597,  864.1509],\n",
      "        [ 256.7324,    3.2108,  360.8389,  103.6730],\n",
      "        [ 434.4647,  512.3389,  546.7449,  625.6791]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9999, 0.9993, 0.9986, 0.9982]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_06-D2(30m)-3.JPG\n",
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 243.9536,  816.3904,  361.9434,  935.1869],\n",
      "        [ 243.3707, 1029.1520,  361.0229, 1149.7257],\n",
      "        [ 243.8519,  596.4310,  361.6493,  711.6952],\n",
      "        [ 238.5025,  104.4926,  352.7036,  214.3154],\n",
      "        [ 236.0727,  346.0701,  374.9922,  472.7106]])), scores: tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9991]), pred_classes: tensor([0, 0, 0, 0, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_09-D2(30m)-4.JPG\n",
      "Instances(num_instances=18, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  67.8589,   83.8314,  179.2785,  196.1404],\n",
      "        [ 246.1706,  976.2117,  356.4732, 1084.9985],\n",
      "        [ 410.1107, 1052.2155,  519.1193, 1160.4747],\n",
      "        [  58.5279,  326.4489,  171.5065,  438.6514],\n",
      "        [ 415.3863,  831.5369,  536.4714,  948.0120],\n",
      "        [  63.9246,  830.8965,  180.9578,  944.2272],\n",
      "        [ 235.4389,   13.9730,  352.2416,  122.9580],\n",
      "        [  82.1574, 1056.0002,  181.1931, 1156.9688],\n",
      "        [ 418.4986,   94.7125,  526.5467,  205.1998],\n",
      "        [ 227.1523,  758.2596,  352.2629,  874.4986],\n",
      "        [ 414.1824,  591.3805,  525.3337,  696.7587],\n",
      "        [ 251.2375,  236.8730,  361.8295,  346.1327],\n",
      "        [ 413.1123,  330.3546,  529.2093,  442.4539],\n",
      "        [ 230.1120,  529.7209,  352.9268,  644.8917],\n",
      "        [ 253.7111,  228.3961,  357.8442,  348.7052],\n",
      "        [ 416.7683,  328.0529,  532.0322,  443.8684],\n",
      "        [ 235.0697,  535.3315,  354.9973,  644.5432],\n",
      "        [ 237.4233,  385.7776,  331.3868,  482.0987]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9998, 0.9997, 0.9997, 0.9996,\n",
      "        0.9995, 0.9995, 0.9975, 0.9443, 0.8885, 0.6322, 0.5714, 0.5647, 0.0763]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1])])\n",
      "Saved: gradcam_results/raw2_09-D2(30m)-1.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 103.3815, 1048.0479,  206.3331, 1151.4368],\n",
      "        [  70.4262,  601.1486,  177.3773,  710.4243],\n",
      "        [ 422.0378, 1056.3512,  524.9641, 1158.2596],\n",
      "        [  84.3485,  840.4478,  196.6257,  948.9610],\n",
      "        [ 425.9371,  598.6613,  540.3309,  711.5679],\n",
      "        [  59.4516,  337.2767,  174.7689,  449.7398],\n",
      "        [ 250.6236,  534.0179,  363.0175,  646.4631],\n",
      "        [ 431.8712,  843.5439,  534.4223,  943.2438],\n",
      "        [ 215.5224,  260.9865,  351.1882,  389.7905],\n",
      "        [ 432.3768,  120.4581,  535.6957,  219.8290],\n",
      "        [ 241.4109,  752.3651,  367.6218,  882.6713],\n",
      "        [ 234.7566,   20.6102,  340.0361,  132.1884],\n",
      "        [ 417.8375,  346.1354,  531.7708,  469.1152],\n",
      "        [ 414.5527,  339.9988,  535.0117,  463.4548],\n",
      "        [ 238.7238,  752.7125,  364.8417,  878.9628],\n",
      "        [ 234.2010,   15.1408,  346.2765,  133.3316],\n",
      "        [ 259.6547,  979.6646,  365.4518, 1088.9596]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9991, 0.9987, 0.9946,\n",
      "        0.9917, 0.9796, 0.9560, 0.7457, 0.6230, 0.4506, 0.3171, 0.0622]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw2_09-D2(30m)-2.JPG\n",
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 431.7454,  537.5735,  547.3493,  654.8776],\n",
      "        [ 430.4362,  298.1362,  545.2000,  411.9066],\n",
      "        [ 265.9057,  696.8063,  382.3607,  811.7488],\n",
      "        [  90.2852,   79.2416,  189.6263,  177.2183],\n",
      "        [ 423.2990,   64.1223,  531.0269,  176.1618],\n",
      "        [ 251.6848,  225.0933,  373.7115,  338.8794],\n",
      "        [  85.5912,  288.4565,  195.8619,  399.8205],\n",
      "        [  89.5352,  783.8127,  209.3709,  900.3956],\n",
      "        [  94.9070, 1017.8815,  207.7705, 1125.8096],\n",
      "        [ 260.7498,  457.8579,  370.6099,  565.2872],\n",
      "        [  92.2989,  547.6003,  202.2318,  660.0994],\n",
      "        [ 244.2190,   20.0242,  365.6053,  139.8043],\n",
      "        [ 433.8760,  779.8249,  547.8013,  898.5672],\n",
      "        [ 255.2832,  921.5920,  370.4621, 1037.5901],\n",
      "        [ 425.6644, 1005.4275,  540.7120, 1115.4539],\n",
      "        [ 426.1576, 1004.4063,  542.5651, 1116.4375]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998,\n",
      "        0.9996, 0.9993, 0.9993, 0.9990, 0.9986, 0.9831, 0.1114]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw2_09-D2(30m)-3.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  94.2199,  804.2525,  198.8980,  907.8664],\n",
      "        [ 410.7144,  790.1566,  517.1733,  894.3068],\n",
      "        [ 247.3004,  699.5924,  362.0097,  810.0927],\n",
      "        [  86.3658,  557.3706,  206.8895,  672.6731],\n",
      "        [ 427.8655,  313.3789,  533.3259,  420.0130],\n",
      "        [ 417.7875,   83.6120,  524.4726,  189.0370],\n",
      "        [  80.1185,  312.8898,  198.3062,  432.9987],\n",
      "        [  82.3565,   90.3523,  196.0184,  202.2765],\n",
      "        [ 411.9378, 1016.1811,  519.1594, 1123.3135],\n",
      "        [  90.6186, 1017.5761,  201.7061, 1131.2509],\n",
      "        [ 247.4471,  937.4667,  354.5034, 1045.8925],\n",
      "        [ 262.2287,  455.6428,  383.7653,  574.6011],\n",
      "        [ 254.6246,  227.4517,  362.9144,  334.7937],\n",
      "        [ 422.8600,  554.4417,  531.9122,  658.4318],\n",
      "        [ 249.9694,    9.2451,  355.6782,  111.7973]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_15-D2(30m)-3.JPG\n",
      "Instances(num_instances=11, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 249.7937,  358.4353,  357.4988,  467.3567],\n",
      "        [ 246.8103,  549.9875,  374.2618,  676.0641],\n",
      "        [ 244.0883,  906.1886,  365.4714, 1027.8519],\n",
      "        [ 240.2062,  196.9299,  364.0587,  298.2613],\n",
      "        [ 250.2853, 1044.5892,  343.6877, 1175.2365],\n",
      "        [ 238.1867,  749.5952,  349.3806,  851.4225],\n",
      "        [ 245.9092,  892.2630,  369.6604, 1026.3745],\n",
      "        [ 248.7910, 1048.3849,  356.3598, 1151.1176],\n",
      "        [ 249.0487,  542.8203,  371.4991,  671.6576],\n",
      "        [ 238.1867,  749.5952,  349.3806,  851.4225],\n",
      "        [ 239.5474,  186.7601,  368.1528,  289.2294]])), scores: tensor([1.0000, 0.8989, 0.7563, 0.6278, 0.5596, 0.4937, 0.3558, 0.2258, 0.1553,\n",
      "        0.1079, 0.1056]), pred_classes: tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0])])\n",
      "Saved: gradcam_results/raw2_15-(D3)24h-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 430.5172,  572.4999,  540.3379,  683.0482],\n",
      "        [ 428.2485,  804.1502,  539.7802,  916.6220],\n",
      "        [  80.1595,   86.1995,  193.9718,  198.7021],\n",
      "        [ 280.9114,  946.0547,  396.5317, 1063.6259],\n",
      "        [ 243.8923,   25.8250,  363.0365,  143.5290],\n",
      "        [ 414.4049,  114.2172,  519.7225,  220.3452],\n",
      "        [  96.1538, 1035.6969,  201.0157, 1139.6537],\n",
      "        [  98.5173,  337.7766,  205.6218,  445.4221],\n",
      "        [  84.1568,  814.5537,  201.0157,  924.5951],\n",
      "        [ 427.9633, 1026.0449,  527.8198, 1125.1074],\n",
      "        [ 424.3705,  336.6541,  538.1053,  449.0020],\n",
      "        [ 253.6290,  510.7603,  360.9676,  618.3846],\n",
      "        [  92.5281,  573.7631,  203.5923,  683.4783],\n",
      "        [ 268.1394,  739.5678,  371.1003,  841.3458],\n",
      "        [ 283.2645,  287.0827,  396.2715,  390.1139],\n",
      "        [ 265.3536,  737.2496,  369.8845,  842.7463]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9999, 0.9998, 0.9998, 0.9991, 0.9899, 0.9818, 0.1590]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])])\n",
      "Saved: gradcam_results/raw2_15-D2(30m)-1.JPG\n",
      "Instances(num_instances=19, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  75.0487, 1018.0953,  177.4984, 1123.3405],\n",
      "        [  65.7059,  324.0404,  173.4890,  432.5501],\n",
      "        [ 392.3897,   83.8852,  503.3755,  193.9972],\n",
      "        [ 237.0866,  929.8537,  350.8321, 1044.1953],\n",
      "        [ 222.8774,  221.6892,  342.8798,  338.1935],\n",
      "        [ 399.0182,  284.7745,  515.5771,  400.2703],\n",
      "        [ 238.7370,   10.1938,  351.1779,  117.1328],\n",
      "        [ 413.3710,  773.2816,  525.2456,  883.4464],\n",
      "        [ 221.6416,  722.2473,  345.0186,  840.3592],\n",
      "        [ 415.0772,  521.2247,  528.7659,  631.1242],\n",
      "        [ 412.3332, 1005.4824,  531.1312, 1116.3965],\n",
      "        [ 245.1505,  451.3563,  359.7090,  564.1527],\n",
      "        [  76.9943,  537.3710,  177.8280,  633.2047],\n",
      "        [ 248.8634,  457.2739,  356.7374,  565.8958],\n",
      "        [  76.7125,  535.3737,  178.2379,  637.2100],\n",
      "        [ 411.8233,  517.0216,  527.9771,  634.1638],\n",
      "        [ 225.4231,  720.0657,  345.2928,  841.8033],\n",
      "        [ 415.2270, 1003.0526,  527.3719, 1119.1256],\n",
      "        [  79.4138,  743.4381,  174.5594,  880.0087]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9997, 0.9996, 0.9989, 0.9969,\n",
      "        0.9834, 0.9813, 0.9114, 0.5394, 0.5170, 0.5099, 0.1278, 0.0812, 0.0715,\n",
      "        0.0508]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw2_15-D2(30m)-2.JPG\n",
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 249.0384,  105.9792,  359.5532,  213.6633],\n",
      "        [ 255.3667, 1012.4951,  371.0405, 1125.1550],\n",
      "        [ 243.5836,  569.7966,  368.0754,  698.7078],\n",
      "        [ 252.0843,  798.9289,  368.5583,  915.6650],\n",
      "        [ 236.6589,  343.3603,  361.6193,  470.8589]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999]), pred_classes: tensor([0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_15-D2(30m)-4.JPG\n",
      "Instances(num_instances=21, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  61.3621,  854.6183,  182.2991,  978.1362],\n",
      "        [ 391.8620,  726.0400,  519.7011,  837.7729],\n",
      "        [  61.4306,  257.3553,  164.9897,  358.2945],\n",
      "        [ 246.6600,  782.0145,  359.5363,  886.6804],\n",
      "        [ 420.0182,  581.4206,  532.0878,  697.6769],\n",
      "        [ 260.3830,  474.1004,  378.6927,  601.1376],\n",
      "        [ 217.8274,  224.6428,  335.8953,  325.6051],\n",
      "        [  74.7179,  496.8005,  186.6165,  608.9783],\n",
      "        [  77.0656, 1005.8108,  191.8208, 1109.1812],\n",
      "        [ 277.5567,  968.9658,  393.6714, 1088.5159],\n",
      "        [ 401.5077,  114.5197,  512.0450,  221.8519],\n",
      "        [ 393.1454,  452.3388,  498.7044,  539.4850],\n",
      "        [ 278.2410,  967.5520,  393.6631, 1090.5132],\n",
      "        [ 254.6438,  447.1061,  370.7392,  600.2223],\n",
      "        [ 402.7879,  112.4900,  513.3749,  220.4288],\n",
      "        [ 416.5609,  585.3555,  536.2493,  695.6924],\n",
      "        [ 221.8040,  222.8012,  337.3185,  324.7639],\n",
      "        [  62.5302,  253.7305,  166.4066,  362.0023],\n",
      "        [ 399.7302,  446.7966,  492.9897,  537.2116],\n",
      "        [ 249.6881,  776.4247,  361.7865,  895.1431],\n",
      "        [  77.3172,  984.8360,  196.0556, 1112.3253]])), scores: tensor([0.9980, 0.9856, 0.9839, 0.9791, 0.9787, 0.9225, 0.9217, 0.8970, 0.8863,\n",
      "        0.7564, 0.7117, 0.5686, 0.5633, 0.4799, 0.3839, 0.1824, 0.1300, 0.0982,\n",
      "        0.0660, 0.0579, 0.0503]), pred_classes: tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_17-(D3)24h-3.JPG\n",
      "Instances(num_instances=6, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 226.5862,  558.7121,  333.0394,  664.7183],\n",
      "        [ 235.5517, 1006.3459,  345.9288, 1118.1349],\n",
      "        [ 225.1088,  320.1391,  336.6589,  432.1796],\n",
      "        [ 225.8954,  791.2058,  336.4142,  901.3319],\n",
      "        [ 231.7161,  105.3423,  332.3961,  206.4631],\n",
      "        [ 225.1986,  104.0456,  332.3505,  205.9327]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.8948, 0.4890]), pred_classes: tensor([0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw2_17-D2(30m)-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=25, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  66.6955,  770.0334,  172.3410,  876.0574],\n",
      "        [ 238.9457,   62.3632,  356.3948,  177.9123],\n",
      "        [ 405.1846, 1020.8737,  530.3940, 1127.7925],\n",
      "        [ 229.4068,  742.8424,  330.7528,  842.8717],\n",
      "        [ 418.1111,  547.0034,  527.6960,  656.4855],\n",
      "        [ 407.3267,  766.0087,  540.1709,  904.6548],\n",
      "        [ 245.9193,  464.5428,  378.2151,  582.0811],\n",
      "        [ 433.6011,  195.8950,  534.4054,  326.2138],\n",
      "        [  82.1093,  302.2768,  178.3881,  410.2104],\n",
      "        [ 402.1025,  673.8315,  500.5288,  786.2505],\n",
      "        [ 239.7253,  940.5430,  339.4542, 1046.8354],\n",
      "        [  90.4044,   84.9621,  195.6848,  202.4831],\n",
      "        [ 280.4427,  247.5859,  384.3782,  348.7325],\n",
      "        [ 409.8941,  757.4606,  532.0326,  906.8175],\n",
      "        [ 122.2497,  197.2355,  219.7655,  318.0174],\n",
      "        [ 240.2795,  502.5972,  352.5657,  594.2490],\n",
      "        [  69.4614,  576.7748,  165.6445,  682.7941],\n",
      "        [ 417.8634,  541.9641,  525.7568,  665.5529],\n",
      "        [ 237.4739,  938.9636,  340.4437, 1046.9896],\n",
      "        [  77.6246,  299.7620,  178.9492,  412.7098],\n",
      "        [  90.4044,   84.9621,  195.6848,  202.4831],\n",
      "        [  75.8512, 1025.5101,  175.6757, 1112.3932],\n",
      "        [ 402.1812, 1001.6548,  533.0506, 1136.5895],\n",
      "        [  64.6160,  766.3973,  172.7688,  875.5478],\n",
      "        [ 238.8525,   64.5619,  355.6884,  178.9866]])), scores: tensor([0.9990, 0.9956, 0.9828, 0.9702, 0.9402, 0.9116, 0.9006, 0.8135, 0.7782,\n",
      "        0.7779, 0.6832, 0.5337, 0.4760, 0.4003, 0.3520, 0.3391, 0.3230, 0.2991,\n",
      "        0.2764, 0.2685, 0.1509, 0.1258, 0.1136, 0.0929, 0.0547]), pred_classes: tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1])])\n",
      "Saved: gradcam_results/raw2_17-(D3)24h-1.JPG\n",
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 243.6985,  777.5242,  369.6956,  904.4496],\n",
      "        [ 245.1080, 1011.7461,  364.4026, 1137.4031],\n",
      "        [ 224.6896,  336.8062,  338.9342,  448.8168],\n",
      "        [ 250.6929,  895.4084,  372.5794, 1021.8073],\n",
      "        [ 224.8016,   93.6229,  353.9664,  212.2964],\n",
      "        [ 234.6941,  232.6235,  345.3583,  347.3463],\n",
      "        [ 220.3604,  331.1621,  330.0636,  442.9329],\n",
      "        [ 262.9281,  388.9152,  382.9848,  506.8016],\n",
      "        [ 228.3871,  561.1106,  363.2983,  693.2843],\n",
      "        [ 221.6578,  566.7324,  350.5349,  689.9147],\n",
      "        [ 245.5828, 1015.4603,  366.0806, 1139.2389],\n",
      "        [ 231.6366,   88.3188,  364.7017,  224.1664],\n",
      "        [ 262.9281,  388.9152,  382.9848,  506.8016],\n",
      "        [ 241.1397,  772.3069,  370.1919,  898.6671],\n",
      "        [ 245.2931,  686.5035,  352.2360,  793.9890],\n",
      "        [ 250.6929,  895.4084,  372.5794, 1021.8073]])), scores: tensor([0.9846, 0.9409, 0.8953, 0.8821, 0.8256, 0.8215, 0.7149, 0.6070, 0.5813,\n",
      "        0.5011, 0.4906, 0.3671, 0.3408, 0.0869, 0.0687, 0.0677]), pred_classes: tensor([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_17-(D3)24h-4.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  85.0535,   67.0389,  195.6890,  179.5386],\n",
      "        [  79.3607, 1006.8904,  181.1771, 1109.8987],\n",
      "        [ 401.4940, 1011.5727,  512.3387, 1120.4421],\n",
      "        [ 229.2501,  924.6176,  347.4808, 1040.2413],\n",
      "        [ 423.6482,  102.3380,  532.5264,  210.2132],\n",
      "        [  74.3569,  283.5573,  188.4499,  396.0568],\n",
      "        [ 245.4983,   32.4233,  355.1522,  143.3081],\n",
      "        [  62.6440,  768.8271,  171.7017,  874.4282],\n",
      "        [ 400.1665,  535.7265,  513.0555,  651.6253],\n",
      "        [  72.8785,  527.8758,  177.5064,  633.2916],\n",
      "        [ 235.0125,  461.5844,  349.9688,  570.4310],\n",
      "        [ 252.5907,  218.5565,  362.8008,  328.3008],\n",
      "        [ 221.8076,  675.4691,  344.1569,  795.7025],\n",
      "        [ 412.5492,  311.0584,  523.4325,  421.6618],\n",
      "        [ 397.0956,  766.9700,  515.9938,  883.5325]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "        0.9999, 0.9999, 0.9995, 0.9994, 0.9992, 0.9977]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_17-D2(30m)-1.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=18, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 235.3192,    6.6575,  339.0695,  110.5114],\n",
      "        [ 232.6865,  177.2377,  349.8262,  293.6679],\n",
      "        [  67.9647,  500.4071,  172.3649,  605.7035],\n",
      "        [  71.2827,   67.2436,  176.1199,  173.8620],\n",
      "        [ 421.8435,  987.9868,  532.1940, 1102.4182],\n",
      "        [  63.2714,  955.7871,  182.3352, 1074.3530],\n",
      "        [ 400.1497,  238.9884,  510.5919,  347.2766],\n",
      "        [ 391.6701,   50.0932,  491.1026,  146.8895],\n",
      "        [ 230.9713,  409.6435,  358.8113,  527.7506],\n",
      "        [  60.8746,  259.2098,  166.2743,  365.4980],\n",
      "        [  73.0523,  732.3369,  168.9819,  834.4584],\n",
      "        [ 226.5700,  875.2527,  362.8637,  982.1045],\n",
      "        [ 232.6417,  650.3207,  349.9241,  760.1053],\n",
      "        [ 408.6840,  465.1191,  516.3541,  574.6627],\n",
      "        [ 292.3745,  867.7151,  416.9475,  975.3205],\n",
      "        [ 231.0950,  650.6487,  346.1770,  759.8517],\n",
      "        [ 409.8387,  463.4289,  521.3069,  576.0166],\n",
      "        [ 291.3303,  866.8083,  416.2651,  979.0411]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9998,\n",
      "        0.9987, 0.9981, 0.9647, 0.9452, 0.8766, 0.7398, 0.4492, 0.3274, 0.2363]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw2_17-D2(30m)-2.JPG\n",
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  65.7660,  728.5501,  177.6097,  842.6850],\n",
      "        [ 229.4571,  908.1332,  335.0257, 1011.1993],\n",
      "        [  73.7666,  499.4380,  182.9807,  605.3386],\n",
      "        [  73.3080,  978.6282,  186.5812, 1087.9144],\n",
      "        [ 401.3117, 1003.9582,  515.5954, 1111.6632],\n",
      "        [ 398.6736,  511.1090,  508.1789,  618.6223],\n",
      "        [ 243.8180,  663.8700,  354.1674,  772.2039],\n",
      "        [ 400.3513,  284.9916,  507.2102,  389.6812],\n",
      "        [ 400.6021,  752.3242,  509.6693,  859.1684],\n",
      "        [ 229.3796,  196.4293,  340.6561,  305.4472],\n",
      "        [ 233.4748,  425.3854,  345.9586,  535.4670],\n",
      "        [  74.8316,  271.0291,  174.8852,  373.5139],\n",
      "        [ 244.0196,   13.5811,  362.1014,  117.5834],\n",
      "        [  72.8691,   69.3563,  173.2465,  167.4371],\n",
      "        [ 412.0263,   82.7022,  520.1507,  188.9691],\n",
      "        [ 410.9240,   82.3641,  520.2270,  192.7618]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "        0.9999, 0.9998, 0.9996, 0.9978, 0.9970, 0.7701, 0.5652]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw2_17-D2(30m)-3.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 234.0310,  799.7106,  352.8682,  917.4470],\n",
      "        [ 246.6694,   96.4581,  359.3239,  204.3968],\n",
      "        [ 245.3080,  322.3153,  363.3707,  434.4221],\n",
      "        [ 245.8699,  562.3583,  358.7404,  670.0724],\n",
      "        [ 229.9176,  995.1809,  343.2023, 1109.1907]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999]), pred_classes: tensor([0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_20-D2(30m)-4.JPG\n",
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 228.3589,   28.3016,  337.2152,  138.8722],\n",
      "        [  74.9482,   84.9303,  185.1696,  192.4387],\n",
      "        [ 229.4189,  241.8086,  337.9710,  349.6866],\n",
      "        [ 391.1070, 1017.6125,  502.2597, 1124.2449],\n",
      "        [ 396.2327,   90.2184,  507.8978,  202.0689],\n",
      "        [ 387.4578,  802.5108,  507.8564,  919.0224],\n",
      "        [  56.2448,  998.2748,  161.3593, 1109.3118],\n",
      "        [ 215.7892,  946.4392,  329.0518, 1059.6484],\n",
      "        [  60.7845,  795.6439,  166.5526,  899.3177],\n",
      "        [ 389.3526,  549.1193,  508.5435,  665.5010],\n",
      "        [ 391.8951,  305.5565,  509.4829,  425.2696],\n",
      "        [ 208.6765,  471.3388,  313.6084,  582.9359],\n",
      "        [ 212.3521,  714.9173,  317.4705,  819.3193],\n",
      "        [  79.0636,  308.4883,  175.0337,  422.3962],\n",
      "        [  58.6217,  553.7765,  152.2746,  651.8015],\n",
      "        [  78.5835,  308.3883,  175.2797,  417.3847],\n",
      "        [ 214.6688,  713.5615,  316.0211,  816.0110]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "        0.9999, 0.9997, 0.9974, 0.9914, 0.7851, 0.6910, 0.6330, 0.1321]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1])])\n",
      "Saved: gradcam_results/raw2_20-D2(30m)-1.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 236.9632,  945.4761,  358.1182, 1063.1273],\n",
      "        [  71.9443,  825.0395,  179.9157,  937.9005],\n",
      "        [ 241.0369,  227.2303,  355.8011,  342.7618],\n",
      "        [ 411.0311,   95.8479,  518.6089,  202.4797],\n",
      "        [  72.0468,   91.5510,  176.6451,  198.7869],\n",
      "        [ 417.9178, 1023.2724,  529.6903, 1136.0630],\n",
      "        [ 233.7939,    7.9826,  356.7739,  123.8307],\n",
      "        [ 231.9059,  478.4744,  361.4750,  598.2651],\n",
      "        [ 419.4888,  566.8897,  529.3289,  676.7841],\n",
      "        [  94.1153, 1043.6748,  196.4165, 1144.3452],\n",
      "        [ 412.7934,  812.3169,  535.5554,  928.1328],\n",
      "        [ 398.9523,  316.2581,  512.1449,  429.5703],\n",
      "        [  67.1900,  578.4594,  168.8409,  679.1264],\n",
      "        [ 249.1535,  682.3871,  367.4366,  805.7783],\n",
      "        [  81.3757,  317.2123,  176.6716,  416.8201]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9997,\n",
      "        0.9997, 0.9996, 0.9980, 0.9967, 0.9677, 0.0815]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])])\n",
      "Saved: gradcam_results/raw2_20-D2(30m)-2.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 430.2472,   70.0837,  543.3824,  183.4828],\n",
      "        [  79.8266, 1019.8224,  186.9920, 1127.4326],\n",
      "        [ 254.4196,  710.2145,  369.9489,  823.7427],\n",
      "        [ 430.5774,  295.2896,  543.0009,  410.3296],\n",
      "        [  81.0368,  801.7008,  197.8588,  913.6002],\n",
      "        [ 265.1927,  236.6164,  378.0167,  352.3086],\n",
      "        [ 264.6638,  477.5610,  381.7684,  592.0881],\n",
      "        [ 247.6300,  948.6849,  357.1196, 1055.3475],\n",
      "        [ 105.7363,   85.4377,  212.5848,  193.3928],\n",
      "        [  89.7680,  561.2758,  204.3955,  676.7676],\n",
      "        [  96.9048,  314.7864,  211.2235,  428.8950],\n",
      "        [ 265.7690,   16.7933,  377.9312,  121.4874],\n",
      "        [ 430.4983,  543.7433,  543.0811,  654.9173],\n",
      "        [ 427.0118,  778.4016,  539.5195,  892.2491],\n",
      "        [ 409.0634, 1009.6028,  523.9396, 1124.0564]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9997]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_20-D2(30m)-3.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  73.5965,  527.8607,  184.8464,  638.4027],\n",
      "        [ 244.5575,  910.3890,  365.7505, 1027.6260],\n",
      "        [ 411.1559,  276.1636,  531.8981,  395.2791],\n",
      "        [  60.0920,  762.3311,  182.5521,  883.3246],\n",
      "        [  78.0576,  994.7658,  189.4993, 1108.9226],\n",
      "        [ 250.2719,    0.0000,  355.8191,  102.3213],\n",
      "        [  77.1297,  279.9165,  198.2355,  402.1078],\n",
      "        [ 419.6058,  782.4928,  532.1106,  895.0869],\n",
      "        [  89.4097,   44.5402,  215.5046,  165.5149],\n",
      "        [ 412.1584,  532.6606,  528.9825,  656.4476],\n",
      "        [ 244.6892,  200.6354,  359.3156,  315.0435],\n",
      "        [ 237.0333,  448.3451,  356.6510,  568.4714],\n",
      "        [ 238.8147,  696.0402,  361.7200,  815.8547],\n",
      "        [ 408.5212, 1003.2718,  525.9338, 1120.8232],\n",
      "        [ 428.1518,   57.5245,  531.9793,  160.1637]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_26-D2(30m)-3.JPG\n",
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 242.9790,  998.6197,  353.3986, 1104.5439],\n",
      "        [ 242.3627,   80.0408,  353.5105,  187.6120],\n",
      "        [ 228.8059,  771.4380,  346.4004,  884.8004],\n",
      "        [ 235.6794,  533.2260,  345.8398,  642.5219],\n",
      "        [ 237.2203,  305.8959,  357.7617,  425.0501]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999]), pred_classes: tensor([0, 0, 0, 0, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_26-D2(30m)-4.JPG\n",
      "Instances(num_instances=14, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 389.7803,  294.6948,  519.2321,  414.6808],\n",
      "        [  56.9901,  766.8427,  165.5082,  875.7797],\n",
      "        [ 228.9405,  212.0317,  331.4614,  318.1089],\n",
      "        [  69.8532,  997.7463,  174.0580, 1099.3010],\n",
      "        [ 216.6956,  677.8117,  329.8753,  796.4272],\n",
      "        [ 393.8773,   77.5445,  512.6140,  190.8496],\n",
      "        [ 393.8632,  772.0494,  512.5751,  888.9087],\n",
      "        [  61.6974,  293.3975,  168.4921,  396.9810],\n",
      "        [ 229.3251,  431.7608,  335.8381,  538.9825],\n",
      "        [ 223.0001,  916.3218,  338.3270, 1030.2531],\n",
      "        [ 405.7046, 1005.0809,  527.0583, 1123.6012],\n",
      "        [ 222.3659,    2.7399,  333.7009,  110.3023],\n",
      "        [ 380.2421,  524.1208,  503.2415,  645.2896],\n",
      "        [  60.2226,   94.7907,  160.1338,  199.8153]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9998,\n",
      "        0.9998, 0.9998, 0.9997, 0.9997, 0.9783]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_26-D2(30m)-1.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  86.5021,  997.8140,  198.7961, 1110.0801],\n",
      "        [  83.9727,  519.0607,  194.4886,  629.8664],\n",
      "        [ 418.2450,  992.7595,  526.7755, 1098.6125],\n",
      "        [ 420.7567,   77.5532,  519.4178,  181.9162],\n",
      "        [ 412.3986,  754.9410,  535.9626,  874.4014],\n",
      "        [ 256.7936,   26.6886,  355.2114,  124.9998],\n",
      "        [ 422.7506,  289.0475,  524.8154,  390.5960],\n",
      "        [ 253.3398,  424.8760,  362.8214,  535.4711],\n",
      "        [ 422.8000,  527.0880,  530.1625,  634.8759],\n",
      "        [  89.2332,  297.1698,  211.3141,  408.8114],\n",
      "        [ 230.7951,  891.1240,  336.8236, 1005.0920],\n",
      "        [  86.2107,  722.1298,  195.3589,  826.4489],\n",
      "        [ 253.4790,  647.6207,  346.8000,  773.5138],\n",
      "        [  86.1599,  721.4211,  196.7962,  827.4369],\n",
      "        [ 257.8460,  190.9254,  377.0282,  304.4579],\n",
      "        [  91.8722,  295.1692,  205.9692,  407.2617],\n",
      "        [ 229.6872,  892.6363,  336.4680, 1004.5923]])), scores: tensor([1.0000, 0.9999, 0.9999, 0.9998, 0.9996, 0.9995, 0.9994, 0.9986, 0.9985,\n",
      "        0.9748, 0.9630, 0.9151, 0.7854, 0.5633, 0.5451, 0.4611, 0.3921]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw2_26-D2(30m)-2.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  78.5392, 1013.7471,  184.4376, 1122.2732],\n",
      "        [ 405.5719,   87.4349,  515.1088,  196.0361],\n",
      "        [ 406.4370,  310.3270,  515.5739,  417.9011],\n",
      "        [ 252.4882,  481.2946,  367.4237,  594.5267],\n",
      "        [ 249.9756,   28.4968,  358.7741,  137.8304],\n",
      "        [ 246.3639,  235.3892,  354.6999,  341.8640],\n",
      "        [  87.1752,   93.0353,  193.8449,  200.2005],\n",
      "        [ 407.1923,  748.8739,  525.9042,  867.4840],\n",
      "        [  71.9423,  560.8104,  191.6647,  674.9358],\n",
      "        [  72.0931,  793.5925,  184.1641,  904.8318],\n",
      "        [ 239.0341,  704.6750,  354.2874,  819.8462],\n",
      "        [ 227.1483,  923.8516,  341.4406, 1034.9911],\n",
      "        [ 390.1541,  989.1403,  507.1245, 1104.3735],\n",
      "        [ 402.1935,  520.8685,  506.4929,  628.6499],\n",
      "        [  74.8865,  323.6127,  187.3074,  433.3058]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9991]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_27-D2(30m)-3.JPG\n",
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  87.2159, 1008.4940,  198.4507, 1121.0897],\n",
      "        [ 246.9942,  704.5109,  359.8433,  818.1077],\n",
      "        [  74.6154,  559.3738,  180.9734,  664.4466],\n",
      "        [ 235.0418,  918.3528,  354.6467, 1031.8809],\n",
      "        [ 240.1515,  475.4357,  350.4233,  582.2034],\n",
      "        [ 412.7145,   95.5736,  513.9018,  198.0102],\n",
      "        [ 408.8849, 1009.4927,  521.4120, 1119.8781],\n",
      "        [  74.7974,  792.1996,  179.2376,  895.2003],\n",
      "        [  75.8610,  320.4071,  182.1449,  428.1747],\n",
      "        [ 400.2152,  553.0924,  521.0197,  673.5089],\n",
      "        [ 418.8728,  326.2682,  525.0092,  432.2303],\n",
      "        [ 229.6533,   29.0407,  350.7129,  145.2384],\n",
      "        [ 410.2405,  783.0479,  516.7277,  890.1340],\n",
      "        [ 248.9566,  245.0750,  354.3880,  345.3279],\n",
      "        [  80.3598,   97.7122,  181.8430,  198.2485],\n",
      "        [  78.0228,   97.7148,  182.9831,  197.6829],\n",
      "        [ 244.9741,  244.6569,  356.0773,  350.0897]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9999, 0.9998, 0.9998, 0.9992, 0.9982, 0.9182, 0.1449, 0.1119]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_27-D2(30m)-1.JPG\n",
      "Instances(num_instances=26, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  90.1239, 1005.6046,  194.0873, 1110.2955],\n",
      "        [ 103.1018,  303.9555,  207.0781,  407.8621],\n",
      "        [  99.2001,   76.5007,  210.9151,  190.1607],\n",
      "        [ 259.2933,  464.3544,  384.2382,  585.9432],\n",
      "        [  93.3898,  533.0754,  200.0698,  648.6525],\n",
      "        [ 266.9985,   28.5163,  381.6674,  140.2012],\n",
      "        [ 239.5873,  912.4349,  373.5502, 1035.4719],\n",
      "        [ 409.3269,  998.9297,  520.4763, 1100.9993],\n",
      "        [  91.8301,  782.6145,  207.8696,  896.1603],\n",
      "        [ 276.2364,  212.9749,  391.6250,  327.3825],\n",
      "        [ 390.4328,  203.6197,  516.3279,  325.7555],\n",
      "        [ 273.1340,  216.0123,  397.8480,  320.2327],\n",
      "        [ 432.1977,   98.8965,  535.7912,  205.9385],\n",
      "        [ 408.4597,  751.6834,  529.5510,  865.3852],\n",
      "        [ 443.9316,  551.4227,  549.1924,  653.5306],\n",
      "        [ 398.8511,  212.3212,  513.3319,  327.0458],\n",
      "        [  91.3327,  528.0742,  198.8817,  655.8835],\n",
      "        [ 413.8882,  998.2324,  519.6902, 1098.0083],\n",
      "        [ 244.5383,  912.6305,  373.5505, 1025.5461],\n",
      "        [ 428.2877,  303.0817,  528.9547,  415.8374],\n",
      "        [ 430.6594,  100.2454,  534.5914,  203.4988],\n",
      "        [  90.1889,  788.7730,  210.6749,  893.4716],\n",
      "        [ 265.6295,   24.6500,  381.8730,  145.3182],\n",
      "        [ 428.2877,  303.0817,  528.9547,  415.8374],\n",
      "        [ 445.0476,  552.4835,  546.8180,  656.2182],\n",
      "        [ 300.6481,  738.8704,  408.9952,  832.0978]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9981, 0.9958, 0.9771, 0.9490, 0.8734,\n",
      "        0.8429, 0.8033, 0.7915, 0.7097, 0.6918, 0.6049, 0.5794, 0.3681, 0.3312,\n",
      "        0.2415, 0.2202, 0.2182, 0.1879, 0.1349, 0.1238, 0.0965, 0.0528]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1])])\n",
      "Saved: gradcam_results/raw2_27-D2(30m)-2.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 234.1617,  978.2512,  346.4326, 1090.4130],\n",
      "        [ 245.8749,  106.9073,  350.4808,  212.3236],\n",
      "        [ 244.2952,  323.0158,  346.1973,  426.2664],\n",
      "        [ 230.1729,  543.7980,  348.3767,  661.4998],\n",
      "        [ 228.2816,  760.6914,  347.6460,  881.3160]])), scores: tensor([1.0000, 1.0000, 0.9998, 0.9997, 0.9976]), pred_classes: tensor([0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_27-D2(30m)-4.JPG\n",
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 243.8739, 1015.9327,  356.1100, 1127.4475],\n",
      "        [ 253.2321,  571.0146,  371.0661,  687.6490],\n",
      "        [ 252.1644,  325.1523,  366.5907,  439.9912],\n",
      "        [ 243.6515,   92.4072,  369.9698,  215.4642],\n",
      "        [ 255.6247,  808.2878,  369.8166,  913.5857]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9999]), pred_classes: tensor([0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_28-D2(30m)-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 250.0587,   57.4370,  352.5200,  159.3629],\n",
      "        [  68.5002,  545.6305,  182.8944,  660.1967],\n",
      "        [ 414.7382,  116.2613,  516.8491,  222.0500],\n",
      "        [  72.8790,   91.3364,  186.7551,  207.4443],\n",
      "        [ 407.4691,  566.1935,  513.5991,  674.5083],\n",
      "        [ 402.5954,  800.6177,  515.5010,  914.1892],\n",
      "        [ 393.7626, 1036.6519,  500.4514, 1137.8740],\n",
      "        [ 404.2393,  345.0607,  510.6924,  448.2863],\n",
      "        [  76.6111,  312.3838,  192.6959,  425.3827],\n",
      "        [ 233.9400,  472.6212,  343.8503,  579.7300],\n",
      "        [ 248.3288,  246.7436,  356.9237,  355.0937],\n",
      "        [  73.6889,  779.1591,  184.5702,  891.7007],\n",
      "        [ 237.0823,  941.3848,  344.1262, 1040.9421],\n",
      "        [  78.6062, 1004.8270,  175.6375, 1106.1183],\n",
      "        [ 250.6675,  715.1194,  360.3548,  816.2962],\n",
      "        [ 252.2165,  715.5599,  358.9160,  820.3999]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9999, 0.9998, 0.9984, 0.6988, 0.1108]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])])\n",
      "Saved: gradcam_results/raw2_28-D2(30m)-1.JPG\n",
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  93.7525, 1037.6593,  196.1765, 1141.3033],\n",
      "        [  73.1619,  575.8934,  184.2805,  689.2674],\n",
      "        [ 244.4174,  739.2916,  355.3618,  848.6465],\n",
      "        [  87.4449,  332.9105,  213.3310,  449.8651],\n",
      "        [ 254.8071,   47.0177,  356.0832,  151.0836],\n",
      "        [ 246.8996,  495.5472,  359.8997,  607.0123],\n",
      "        [ 409.3913, 1046.1838,  516.4811, 1150.2571],\n",
      "        [  83.1423,  108.5001,  195.7809,  218.1279],\n",
      "        [ 246.0928,  268.2762,  364.5000,  379.9008],\n",
      "        [ 247.9878,  966.7307,  354.1184, 1069.9270],\n",
      "        [ 414.5785,  569.7762,  528.1792,  683.2320],\n",
      "        [  83.7158,  818.2281,  186.2293,  920.6587],\n",
      "        [ 412.7874,  101.0428,  527.9984,  207.9713],\n",
      "        [ 415.9374,  821.9301,  518.2982,  919.3071],\n",
      "        [ 416.3418,  337.3872,  532.2513,  446.3871],\n",
      "        [ 418.6544,  338.4655,  529.8247,  448.1204],\n",
      "        [ 416.3450,  822.9202,  517.1756,  919.2803]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9999, 0.9997, 0.9941, 0.9930, 0.1455, 0.0748]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_28-D2(30m)-2.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 255.6647,  250.4843,  379.5493,  379.8560],\n",
      "        [  93.3464, 1046.3096,  195.4713, 1150.9751],\n",
      "        [ 267.0211,  503.6953,  376.4273,  612.4217],\n",
      "        [  93.7905,  593.8877,  199.5509,  699.0869],\n",
      "        [  94.6011,  830.3058,  198.3458,  933.4650],\n",
      "        [ 421.5931,  332.3217,  532.3400,  442.0270],\n",
      "        [ 247.4695,  959.8430,  359.2894, 1073.2906],\n",
      "        [ 420.6533,  578.2457,  531.4585,  686.5701],\n",
      "        [ 247.2761,  741.5020,  361.0499,  854.3761],\n",
      "        [  83.8042,  102.1225,  194.6178,  215.4424],\n",
      "        [ 415.1886,  103.4827,  519.7570,  209.4669],\n",
      "        [  92.9365,  345.1876,  201.7621,  453.2256],\n",
      "        [ 412.4456,  818.8552,  525.9455,  928.5178],\n",
      "        [ 404.6068, 1036.3420,  513.8792, 1144.6091],\n",
      "        [ 250.2739,   19.2054,  366.1958,  139.1920]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw2_28-D2(30m)-3.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=13, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 229.9563,  737.6389,  358.4994,  861.4963],\n",
      "        [ 249.0749,  934.1306,  364.8547, 1042.3871],\n",
      "        [ 249.0009,    0.0000,  361.4685,  116.4908],\n",
      "        [ 229.8577,  511.5721,  338.0495,  616.4056],\n",
      "        [ 240.3374,  293.7946,  356.1306,  402.5737],\n",
      "        [ 245.2651,   76.6033,  361.4550,  177.6407],\n",
      "        [ 259.6552, 1082.4620,  363.3971, 1177.9188],\n",
      "        [ 258.1795,  612.4133,  367.8300,  716.9026],\n",
      "        [ 241.4687,  290.5787,  353.3380,  418.1377],\n",
      "        [ 259.6552, 1082.4620,  363.3971, 1177.9188],\n",
      "        [ 231.1415,  506.6360,  336.0333,  621.8361],\n",
      "        [ 248.6570,   77.9015,  359.9593,  182.7176],\n",
      "        [ 248.6521,  932.9957,  367.3354, 1051.5211]])), scores: tensor([0.9998, 0.9950, 0.9925, 0.9701, 0.9227, 0.7998, 0.6377, 0.3887, 0.2552,\n",
      "        0.2016, 0.1494, 0.0974, 0.0575]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw2_29-(D3)24h-4.JPG\n",
      "Instances(num_instances=18, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  45.2357,  789.8657,  165.0361,  910.1165],\n",
      "        [  61.7321,  312.0641,  173.1419,  423.3803],\n",
      "        [  58.0150, 1008.0970,  161.6307, 1111.1095],\n",
      "        [ 392.0372, 1004.9008,  516.6584, 1123.8539],\n",
      "        [ 381.3507,  326.0592,  501.1159,  440.9252],\n",
      "        [ 406.2061,  794.5206,  529.3759,  911.1554],\n",
      "        [ 217.2957,  449.3980,  338.4597,  570.8815],\n",
      "        [ 234.2834,  686.8075,  359.4375,  813.2559],\n",
      "        [ 214.1079,  918.7845,  348.7183, 1046.7922],\n",
      "        [ 399.2880,  552.9009,  518.0970,  675.8239],\n",
      "        [ 412.7983,  109.5148,  512.6085,  211.7825],\n",
      "        [  79.1560,   90.0022,  185.5380,  185.6806],\n",
      "        [ 242.7700,   37.6087,  347.2927,  133.0525],\n",
      "        [  64.2849,  538.0717,  168.4175,  651.4522],\n",
      "        [  62.2186,  537.5108,  169.1317,  655.9568],\n",
      "        [ 245.4293,   39.1492,  350.0213,  137.1778],\n",
      "        [ 412.4910,  108.9194,  515.0666,  216.3743],\n",
      "        [  76.2896,   89.0543,  180.5410,  184.5538]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9998, 0.9996,\n",
      "        0.9994, 0.9978, 0.9843, 0.9215, 0.8236, 0.1653, 0.1560, 0.1403, 0.0901]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw2_29-D2(30m)-1.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 242.1288,  240.3112,  355.5267,  354.1726],\n",
      "        [  80.9562, 1013.8315,  187.8882, 1121.2012],\n",
      "        [ 411.9765,  317.2197,  521.0862,  423.4897],\n",
      "        [ 263.3370,   37.1567,  372.5752,  147.5320],\n",
      "        [ 417.6700, 1005.9295,  527.7198, 1117.7865],\n",
      "        [ 237.6918,  925.0795,  344.4338, 1032.6735],\n",
      "        [ 411.4344,  549.1300,  527.4501,  663.0914],\n",
      "        [  61.3306,  331.7575,  172.3845,  439.1998],\n",
      "        [ 414.5057,   93.6450,  516.2088,  195.7866],\n",
      "        [ 401.7451,  787.1450,  514.3221,  898.6644],\n",
      "        [ 234.9995,  469.5083,  343.9180,  585.0425],\n",
      "        [ 206.5792,  695.6567,  316.4030,  809.9816],\n",
      "        [  47.6268,  566.4334,  154.7079,  682.3672],\n",
      "        [ 205.0246,  687.8120,  314.9187,  808.5925],\n",
      "        [  48.5291,  566.9977,  154.4734,  681.0366]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9998, 0.9997, 0.9996,\n",
      "        0.9994, 0.9984, 0.9716, 0.9201, 0.2939, 0.1796]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])])\n",
      "Saved: gradcam_results/raw2_29-D2(30m)-2.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=16, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 241.7048,  458.2991,  358.4498,  569.6030],\n",
      "        [  94.6435,   91.9948,  196.6272,  192.5932],\n",
      "        [ 253.9522,   24.1827,  365.0352,  137.5834],\n",
      "        [  77.0748,  555.3130,  185.6708,  663.3561],\n",
      "        [ 403.2403,  277.9398,  522.9240,  395.3143],\n",
      "        [ 246.3683,  223.8195,  363.2568,  341.9047],\n",
      "        [  78.0179,  296.6101,  195.6312,  411.9578],\n",
      "        [ 241.4701,  921.7885,  346.2828, 1020.1972],\n",
      "        [  65.9408,  789.4668,  175.8197,  903.1324],\n",
      "        [ 400.7116,  524.0005,  518.4731,  639.4725],\n",
      "        [  77.5755,  995.6056,  194.9892, 1110.7155],\n",
      "        [ 399.3544,  765.5027,  518.6035,  883.1328],\n",
      "        [ 402.2366,  993.6895,  512.7903, 1104.2036],\n",
      "        [ 222.1110,  717.0840,  344.5232,  833.0933],\n",
      "        [ 413.7421,   61.5740,  519.1287,  162.8452],\n",
      "        [ 409.2960,   56.5622,  520.8473,  163.3459]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9998, 0.9998, 0.9998, 0.9995, 0.9990, 0.9697, 0.2897]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw2_29-D2(30m)-3.JPG\n",
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 236.8244,  261.9558,  360.3760,  374.8506],\n",
      "        [ 225.4048,  490.6730,  354.0424,  611.0167],\n",
      "        [ 232.9485,  733.5652,  351.9626,  852.3282],\n",
      "        [ 229.0509,  956.7931,  355.7493, 1086.8733],\n",
      "        [ 249.9644,   48.9770,  371.0074,  165.7798]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9996]), pred_classes: tensor([0, 0, 0, 0, 0])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_29-D2(30m)-4.JPG\n",
      "Instances(num_instances=18, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 231.3723,  704.4670,  346.0341,  818.5493],\n",
      "        [  64.8687,  331.7641,  165.3990,  430.8765],\n",
      "        [ 388.8514, 1031.1332,  492.2904, 1130.6051],\n",
      "        [ 219.1473,  464.6752,  332.9724,  579.1742],\n",
      "        [ 395.8242,  803.6318,  506.2075,  912.8565],\n",
      "        [  70.5639,  113.9718,  169.7964,  216.2124],\n",
      "        [ 239.8496,  937.4122,  334.0987, 1035.3086],\n",
      "        [ 401.3071,  331.2917,  516.6531,  446.3405],\n",
      "        [ 398.2245,  574.7784,  506.2981,  682.2445],\n",
      "        [  49.8533,  557.8002,  161.8340,  666.4875],\n",
      "        [ 400.7278,  118.2216,  501.7372,  214.1469],\n",
      "        [ 225.5102,  241.7330,  346.8214,  363.3451],\n",
      "        [ 218.8895,    9.6554,  332.0213,  135.6095],\n",
      "        [  79.6221,  763.5645,  191.6361,  869.2967],\n",
      "        [  70.8229, 1019.1682,  181.8446, 1130.2393],\n",
      "        [  71.3195, 1015.1608,  177.2717, 1128.0913],\n",
      "        [ 221.1343,   16.7888,  334.1081,  135.8078],\n",
      "        [ 224.7485,  236.9034,  343.8300,  362.5792]])), scores: tensor([1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9996, 0.9995, 0.9994, 0.9994,\n",
      "        0.9991, 0.9989, 0.9989, 0.9876, 0.9740, 0.8805, 0.2087, 0.1663, 0.1460]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])])\n",
      "Saved: gradcam_results/raw1_02-D2(30m)-2.JPG\n",
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  71.5611, 1001.2941,  181.1771, 1110.1759],\n",
      "        [ 217.3477,  440.2660,  337.6909,  558.6728],\n",
      "        [  93.2385,   91.7725,  199.7211,  194.4961],\n",
      "        [ 228.7125,  919.6924,  340.5406, 1029.2327],\n",
      "        [ 224.3427,  666.2624,  342.6743,  784.5154],\n",
      "        [ 378.0659,  535.9069,  487.7302,  643.5771],\n",
      "        [  56.4321,  539.0917,  170.3954,  653.6089],\n",
      "        [ 385.0981,  305.3424,  495.7831,  417.1616],\n",
      "        [ 372.0783,  773.4981,  480.3452,  883.3337],\n",
      "        [ 397.8867,   83.7108,  510.3804,  190.8197],\n",
      "        [ 381.7125, 1006.9140,  493.6119, 1118.8961],\n",
      "        [  76.8303,  320.1689,  176.8234,  421.4445],\n",
      "        [ 239.3022,  222.9284,  342.9439,  323.5215],\n",
      "        [ 246.3834,    4.0282,  363.8167,  114.4689],\n",
      "        [  73.0605,  789.2859,  174.1814,  888.2852]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9998, 0.9995, 0.9988, 0.9968]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw1_02-D2(30m)-3.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=5, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 256.9693,  554.3986,  367.3131,  664.7381],\n",
      "        [ 256.4629,  327.7039,  366.9087,  434.4178],\n",
      "        [ 242.5490,   88.7698,  360.1363,  206.1023],\n",
      "        [ 257.3439,  780.7933,  361.6508,  888.4248],\n",
      "        [ 246.4601,  984.3649,  360.0866, 1095.3982]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9999]), pred_classes: tensor([0, 0, 0, 0, 0])])\n",
      "Saved: gradcam_results/raw1_02-D2(30m)-4.JPG\n",
      "Instances(num_instances=27, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[7.4532e+01, 1.0154e+03, 1.9056e+02, 1.1292e+03],\n",
      "        [2.6075e+02, 9.4500e+02, 3.7628e+02, 1.0617e+03],\n",
      "        [4.2259e+02, 1.0524e+03, 5.3213e+02, 1.1597e+03],\n",
      "        [1.1261e+02, 7.5269e+02, 2.3152e+02, 8.6754e+02],\n",
      "        [6.5265e+01, 5.5871e+02, 1.7988e+02, 6.7013e+02],\n",
      "        [4.2775e+02, 3.2901e+02, 5.3516e+02, 4.3514e+02],\n",
      "        [1.1447e+02, 8.2336e+01, 2.1679e+02, 1.8368e+02],\n",
      "        [6.3815e+01, 2.9671e+02, 1.7433e+02, 4.1861e+02],\n",
      "        [2.7774e+02, 2.1730e+02, 3.7533e+02, 3.1812e+02],\n",
      "        [4.2856e+02, 1.8979e+02, 5.3370e+02, 2.9284e+02],\n",
      "        [4.4736e+02, 8.7868e+02, 5.4872e+02, 9.8323e+02],\n",
      "        [3.8297e+02, 6.8781e+02, 5.0217e+02, 7.9699e+02],\n",
      "        [4.1981e+02, 5.7126e+02, 5.1761e+02, 6.6782e+02],\n",
      "        [4.3831e+02, 8.8628e+01, 5.4534e+02, 1.9141e+02],\n",
      "        [2.7459e+02, 1.3584e-02, 3.8065e+02, 9.9802e+01],\n",
      "        [3.4081e+02, 4.4320e+02, 4.4173e+02, 5.2874e+02],\n",
      "        [6.2583e+01, 2.8838e+02, 1.6871e+02, 4.1620e+02],\n",
      "        [4.3667e+02, 8.9294e+01, 5.4491e+02, 1.8654e+02],\n",
      "        [4.4862e+02, 8.7798e+02, 5.4673e+02, 9.7797e+02],\n",
      "        [2.7678e+02, 2.1896e+02, 3.7230e+02, 3.1651e+02],\n",
      "        [2.6864e+02, 1.0923e-01, 3.7975e+02, 9.7618e+01],\n",
      "        [3.8514e+02, 6.9353e+02, 5.0405e+02, 7.9572e+02],\n",
      "        [1.0899e+02, 7.5112e+02, 2.3355e+02, 8.6716e+02],\n",
      "        [1.1288e+02, 7.8639e+01, 2.1610e+02, 1.8415e+02],\n",
      "        [4.2691e+02, 3.2356e+02, 5.3665e+02, 4.3356e+02],\n",
      "        [4.1981e+02, 5.7126e+02, 5.1761e+02, 6.6782e+02],\n",
      "        [6.3771e+01, 5.5925e+02, 1.8014e+02, 6.6849e+02]])), scores: tensor([1.0000, 0.9999, 0.9997, 0.9996, 0.9975, 0.9915, 0.9905, 0.9780, 0.9581,\n",
      "        0.8897, 0.8690, 0.8287, 0.7990, 0.7942, 0.6964, 0.6641, 0.5204, 0.4925,\n",
      "        0.3094, 0.2722, 0.2480, 0.2087, 0.1280, 0.1105, 0.0984, 0.0747, 0.0515]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw1_02-D3(24h)-1.JPG\n",
      "Instances(num_instances=13, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 243.5707, 1003.2018,  366.7216, 1125.8949],\n",
      "        [ 241.3515,   80.5384,  372.4961,  208.2761],\n",
      "        [ 247.8833,  727.1516,  366.7409,  836.0186],\n",
      "        [ 245.2882,  552.2015,  365.2310,  668.9342],\n",
      "        [ 234.5054,  341.5987,  356.4450,  457.7009],\n",
      "        [ 245.5444,  507.5775,  371.7844,  635.5839],\n",
      "        [ 238.1462,  297.9310,  355.0374,  408.9887],\n",
      "        [ 240.6916,  798.5199,  353.7675,  912.8962],\n",
      "        [ 240.6916,  798.5199,  353.7675,  912.8962],\n",
      "        [ 244.2819,  553.2513,  360.6942,  672.4617],\n",
      "        [ 239.0057,  335.8510,  346.9568,  469.1100],\n",
      "        [ 242.2678,  510.2032,  364.9954,  625.4700],\n",
      "        [ 254.0049,  731.9182,  365.4631,  833.6389]])), scores: tensor([1.0000, 0.9999, 0.9911, 0.9747, 0.9666, 0.6923, 0.3741, 0.2743, 0.2152,\n",
      "        0.1613, 0.1478, 0.1417, 0.0619]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw1_02-D3(24h)-4.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=13, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 245.9615,  707.2903,  367.3765,  832.0807],\n",
      "        [ 236.4937,  999.9089,  357.8369, 1109.8191],\n",
      "        [ 239.4290,  530.1555,  363.7381,  645.7405],\n",
      "        [ 241.4951,  281.9655,  370.4108,  428.6078],\n",
      "        [ 242.5217,  275.3396,  370.2727,  413.8956],\n",
      "        [ 250.1685,  433.3153,  371.7965,  537.9316],\n",
      "        [ 249.3507,    0.0000,  375.0056,  125.6609],\n",
      "        [ 242.6943,  880.9062,  361.5560,  973.9417],\n",
      "        [ 237.4040,  511.1281,  361.0320,  644.5662],\n",
      "        [ 240.6844,  706.3695,  366.4760,  836.5470],\n",
      "        [ 241.1780, 1002.4901,  357.3025, 1122.3986],\n",
      "        [ 252.1496,  168.7305,  365.1082,  279.7702],\n",
      "        [ 248.8627,  605.7621,  361.8766,  735.4530]])), scores: tensor([0.9443, 0.9371, 0.9321, 0.8431, 0.7506, 0.7067, 0.6327, 0.5428, 0.2924,\n",
      "        0.1915, 0.1463, 0.1278, 0.0967]), pred_classes: tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])])\n",
      "Saved: gradcam_results/raw2_33-(D3)24h-4.JPG\n",
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 246.1940,  464.8853,  353.4894,  571.4781],\n",
      "        [  87.7985, 1030.9526,  195.9675, 1140.0452],\n",
      "        [ 247.8064,  933.7922,  361.0984, 1048.1313],\n",
      "        [ 233.4364,  709.8929,  344.1215,  818.9564],\n",
      "        [  64.7677,  554.9211,  179.9380,  666.3857],\n",
      "        [ 408.1803,  553.4413,  518.6113,  664.6063],\n",
      "        [  77.6430,  793.8525,  192.2865,  908.0701],\n",
      "        [ 409.1903,  792.5765,  517.8768,  897.4456],\n",
      "        [  72.4217,  300.8102,  185.4742,  415.5473],\n",
      "        [ 412.5693, 1016.4530,  532.5624, 1131.0778],\n",
      "        [ 404.8737,   84.1920,  521.1358,  193.1797],\n",
      "        [ 418.5953,  316.5472,  519.2943,  414.7137],\n",
      "        [ 258.3582,    8.6984,  362.4820,  121.0778],\n",
      "        [  71.6767,   69.6098,  199.7639,  183.5621],\n",
      "        [ 262.6281,  234.9362,  365.6489,  341.1516],\n",
      "        [  71.5638,   67.8558,  196.7451,  186.1361],\n",
      "        [  81.8833,   72.6323,  146.5566,  185.0179]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9998, 0.9998, 0.9996, 0.9976, 0.8747, 0.6070, 0.4020, 0.0578]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: gradcam_results/raw2_33-D2(30m)-1.JPG\n",
      "Instances(num_instances=17, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 101.8990, 1041.0977,  216.5434, 1153.6797],\n",
      "        [ 269.6308,  949.0531,  387.7348, 1064.3497],\n",
      "        [ 103.5645,   75.8946,  223.5147,  192.7368],\n",
      "        [ 286.5324,  223.7887,  395.5362,  332.5936],\n",
      "        [ 114.5212,  809.6195,  219.2520,  915.3647],\n",
      "        [ 281.8674,  475.6057,  392.0549,  588.1415],\n",
      "        [ 288.6986,   29.5602,  391.8347,  133.3664],\n",
      "        [ 436.4666,  798.5922,  544.2048,  908.9470],\n",
      "        [ 115.3022,  555.1224,  231.7346,  674.2962],\n",
      "        [ 424.0859, 1038.2909,  532.4033, 1147.3600],\n",
      "        [ 107.1972,  309.4759,  220.9165,  428.0770],\n",
      "        [ 451.6265,  553.7427,  560.8732,  661.7131],\n",
      "        [ 441.6367,  318.1790,  550.5688,  424.6299],\n",
      "        [ 445.0392,   88.8733,  546.5665,  191.8780],\n",
      "        [ 260.7836,  722.6973,  382.2577,  838.5428],\n",
      "        [ 264.3228,  725.3308,  382.1472,  836.7008],\n",
      "        [ 443.8630,   89.7468,  546.4546,  190.9584]])), scores: tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9998, 0.9997, 0.9996, 0.9996, 0.9920, 0.9414, 0.4219, 0.2546]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1])])\n",
      "Saved: gradcam_results/raw2_33-D2(30m)-2.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=15, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[  77.9741,   89.5493,  189.0560,  198.2327],\n",
      "        [ 227.9717,  251.2907,  338.6708,  363.3689],\n",
      "        [  64.0426, 1054.7024,  174.7065, 1160.5259],\n",
      "        [ 220.5112,  493.1717,  341.6058,  609.9316],\n",
      "        [ 242.9985,   28.3140,  351.6193,  135.8366],\n",
      "        [  61.7899,  571.4565,  166.4250,  679.9094],\n",
      "        [  72.5173,  329.3063,  178.9606,  440.0562],\n",
      "        [ 381.1533,  578.4744,  488.0297,  683.3624],\n",
      "        [ 205.0098,  720.3322,  322.9976,  839.0151],\n",
      "        [  58.9052,  821.3240,  165.6692,  927.5817],\n",
      "        [ 391.1553,  333.7448,  506.4654,  445.8027],\n",
      "        [ 394.1508,   98.1355,  508.2901,  212.2295],\n",
      "        [ 373.3104,  804.4122,  471.9643,  903.1134],\n",
      "        [ 211.8989,  958.5550,  329.5868, 1085.9368],\n",
      "        [ 211.8501,  963.6202,  329.8938, 1087.4058]])), scores: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9999, 0.9998, 0.9998, 0.8151, 0.4260]), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])])\n",
      "Saved: gradcam_results/raw2_33-D2(30m)-3.JPG\n",
      "Instances(num_instances=6, image_height=1200, image_width=600, fields=[pred_boxes: Boxes(tensor([[ 248.2824, 1043.4731,  362.0824, 1152.0261],\n",
      "        [ 235.7980,  829.7900,  349.9661,  939.7714],\n",
      "        [ 231.0674,  347.2323,  357.3746,  476.1105],\n",
      "        [ 238.4752,   85.6485,  361.2270,  208.0666],\n",
      "        [ 233.0483,  600.1442,  350.2694,  714.3359],\n",
      "        [ 232.5034,  597.9234,  351.4057,  724.2255]])), scores: tensor([1.0000, 1.0000, 0.9999, 0.9999, 0.9996, 0.0752]), pred_classes: tensor([0, 0, 0, 0, 0, 1])])\n",
      "Saved: gradcam_results/raw2_33-D2(30m)-4.JPG\n"
     ]
    }
   ],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog\n",
    "\n",
    "from dataset.utils import register_patch_bin_dataset\n",
    "\n",
    "\n",
    "cfg_path = \"/workspace/project/configs/frcnn/frcnn.yaml\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\n",
    "        \"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"\n",
    "))\n",
    "\n",
    "cfg.set_new_allowed(True)\n",
    "cfg.defrost()\n",
    "cfg.merge_from_file(cfg_path)\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"/workspace/project/record/debug2/result_single/frcnn_vis/model_final.pth\"\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "\n",
    "cfg.freeze()\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "model = predictor.model\n",
    "model.eval()\n",
    "\n",
    "target_layer = model.backbone.bottom_up.res5[-1]\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "register_patch_bin_dataset(\n",
    "        cfg.DATASETS.TEST[0],\n",
    "        json_file=cfg.DATASETS.TEST_ANNO_DIR,\n",
    "        img_root=cfg.DATASETS.IMG_DIR,\n",
    "        extra_key=[\"patient_id\"]\n",
    ")\n",
    "\n",
    "ds_dicts = DatasetCatalog.get(cfg.DATASETS.TEST[0])\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
    "\n",
    "out_dir = \"./gradcam_results\"\n",
    "\n",
    "for i, entry in enumerate(ds_dicts):\n",
    "        visualize_cam_and_bboxes(entry, model, gradcam, metadata, out_dir)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e59c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "img_path = \"/workspace/datasets/seg_by_patient/preprocessed/pos_cropped_patch_all_r1_r2/raw1_01-D2(30m)-1.JPG\"\n",
    "# Prepare image\n",
    "img = cv2.imread(img_path)[:, :, ::-1]  # BGR->RGB\n",
    "\n",
    "img = minmax_norm(img)\n",
    "\n",
    "# inputs = predictor.transform_gen.get_transform(img).apply_image(img)\n",
    "tensor = torch.as_tensor(img.transpose(2,0,1)).cuda().float()\n",
    "\n",
    "input = [{\n",
    "    \"image\":tensor,\n",
    "    \"height\": 1200,\n",
    "    \"width\": 600\n",
    "}]\n",
    "\n",
    "# print(tensor.shape)\n",
    "\n",
    "# Generate CAM\n",
    "cam_map = gradcam(input)\n",
    "\n",
    "# Overlay heatmap\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam_map), cv2.COLORMAP_JET)\n",
    "\n",
    "H, W, _ = img.shape\n",
    "\n",
    "r_hm = cv2.resize(heatmap, (W, H))\n",
    "\n",
    "r_hm = (r_hm-r_hm.min()) / (r_hm.max()-r_hm.min()+1e-8)\n",
    "\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * r_hm), cv2.COLORMAP_JET)\n",
    "\n",
    "\n",
    "overlay = 0.5 * heatmap[:, :, ::-1] + 0.5 * img\n",
    "cv2.imwrite(\"./gradcam_custom.jpg\", overlay[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90cf12d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 19, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1b15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
